2024-01-02 01:17:25.439169: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-01-02 01:17:26.772470: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-01-02 01:17:26.772598: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-01-02 01:17:26.941789: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-01-02 01:17:27.372307: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-02 01:17:30.756717: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/home/uceezw9/.conda/envs/aml-final/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1702400366987/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)
  return F.conv2d(input, weight, bias, self.stride,
The device used for training is cuda:0
Epoch 1/50, Loss: 0.5927296876907349
val_loss:0.3576003611087799
Validation Accuracy: 82.20
Epoch 2/50, Loss: 0.5052307844161987
val_loss:0.4390431046485901
Validation Accuracy: 86.34
Epoch 3/50, Loss: 0.32705387473106384
val_loss:0.37423041462898254
Validation Accuracy: 88.04
Epoch 4/50, Loss: 0.4231105446815491
val_loss:0.2505604922771454
Validation Accuracy: 89.56
Epoch 5/50, Loss: 0.13407287001609802
val_loss:0.2803605794906616
Validation Accuracy: 89.90
Epoch 6/50, Loss: 0.16319532692432404
val_loss:0.25432270765304565
Validation Accuracy: 89.93
Epoch 7/50, Loss: 0.18810638785362244
val_loss:0.23074571788311005
Validation Accuracy: 90.30
Epoch 8/50, Loss: 0.3245341181755066
val_loss:0.1634257435798645
Validation Accuracy: 91.69
Epoch 9/50, Loss: 0.12624812126159668
val_loss:0.26240074634552
Validation Accuracy: 91.49
Epoch 10/50, Loss: 0.14284290373325348
val_loss:0.22841285169124603
Validation Accuracy: 91.22
Epoch 11/50, Loss: 0.08573537319898605
val_loss:0.3788899779319763
Validation Accuracy: 91.84
Epoch 12/50, Loss: 0.08322490006685257
val_loss:0.29777735471725464
Validation Accuracy: 91.71
Epoch 13/50, Loss: 0.01628095656633377
val_loss:0.4937119483947754
Validation Accuracy: 92.18
Epoch 14/50, Loss: 0.0344734713435173
val_loss:0.2983648180961609
Validation Accuracy: 91.39
Epoch 15/50, Loss: 0.01973232626914978
val_loss:0.2535315155982971
Validation Accuracy: 92.02
Epoch 16/50, Loss: 0.01892300695180893
val_loss:0.37939712405204773
Validation Accuracy: 91.95
Epoch 17/50, Loss: 0.029545746743679047
val_loss:0.14980414509773254
Validation Accuracy: 92.29
Epoch 18/50, Loss: 0.13699176907539368
val_loss:0.2843095660209656
Validation Accuracy: 92.18
Epoch 19/50, Loss: 0.02444760501384735
val_loss:0.34054189920425415
Validation Accuracy: 91.98
Early stopped training at epoch 18
Best Epoch is 7
Accuracy: 0.7680
Recall: 0.7680
Precision: 0.7910
test_loss:0.8182798027992249
Test Accuracy: 0.77
